{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <p style=\"text-align: center;\">RNA Knowledge Graph Build Data Preparation</p>\n",
    "    \n",
    "***\n",
    "***\n",
    "\n",
    "**Authors:** [ECavalleri](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=emanuele.cavalleri@unimi.it), [TJCallahan](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=callahantiff@gmail.com), [MMesiti](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=marco.mesiti@unimi.it)\n",
    "\n",
    "**GitHub Repositories:** [testRNA-KG](https://github.com/emanuelecavalleri/testRNA-KG), [PheKnowLator](https://github.com/callahantiff/PheKnowLator/)  \n",
    "<!--- **Release:** **[v2.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)** --->\n",
    "  \n",
    "<br>  \n",
    "  \n",
    "**Purpose:** This notebook serves as a script to download, process, map, and clean data in order to build edges for the simplified RNA-centered Knowledge Graph.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumptions:**   \n",
    "- Edge data downloads ➞ `./resources/edge_data`  \n",
    "- Ontologies ➞ `./resources/ontologies`    \n",
    "- Processed data write location ➞ `./resources/processed_data`  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Dependencies:**   \n",
    "- **Scripts**: This notebook utilizes several helper functions, which are stored in the [`data_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/data_utils.py) and [`kg_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/kg_utils.py) scripts.  \n",
    "- **Data**: All downloaded and generated data sources are provided through [this](https://drive.google.com/drive/folders/1sev5zczMviX7UVqMhTpkFXG43K3nQa9f) dedicated Google Drive repository. <u>This notebook will download everything that is needed for you</u>.  \n",
    "_____\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "***\n",
    "\n",
    "### [Download Ontologies](#create-ontologies)\n",
    "\n",
    "\n",
    "### [Create Identifier Maps ](#create-identifier-maps)   \n",
    "\n",
    "\n",
    "### [Download and process Edge Datasets](#create-edges)  \n",
    "\n",
    "____\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up Environment\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import datetime\n",
    "import glob\n",
    "import itertools\n",
    "import networkx\n",
    "import numpy\n",
    "import os\n",
    "import openpyxl\n",
    "import pandas\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from reactome2py import content\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "\n",
    "from pkt_kg.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import gffpandas.gffpandas as gffpd\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to store resources\n",
    "resource_data_location = '../resources/'\n",
    "\n",
    "# directory to use for processing data\n",
    "processed_data_location = '../resources/processed_data/'\n",
    "\n",
    "# directory to write ontology data to\n",
    "ontology_data_location = '../resources/ontologies/'\n",
    "\n",
    "# directory to write edges data to\n",
    "edge_data_location = '../resources/edge_data/'\n",
    "\n",
    "# owltools location\n",
    "owltools_location = '../pkt_kg/libs/owltools'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data function for already processed data\n",
    "def download(name, path):\n",
    "    url = 'https://storage.googleapis.com/pheknowlator/current_build/data/processed_data/'+name\n",
    "    #if not os.path.exists(path + name):\n",
    "    data_downloader(url, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### DOWNLOAD ONTOLOGIES  <a class=\"anchor\" id=\"create-ontologies\"></a>\n",
    "We must establish a unified standard for identifying entities within our simplified RNA-centered KG. Entities are relations, diseases, miRNAs, and genes. While well-reputed bio-ontologies provide terms for relations and diseases, miRNAs and genes lack direct correspondences.\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation Ontology ([RO](https://www.ebi.ac.uk/ols/ontologies/ro))\n",
    "The OBO Relations Ontology (RO) is a collection of OWL relations (ObjectProperties) intended for use across a wide variety of biological ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ontology_data_location + 'ro_with_imports.owl'):\n",
    "    command = '{} {} --merge-import-closure -o {}'\n",
    "    os.system(command.format(owltools_location, 'http://purl.obolibrary.org/obo/ro.owl',\n",
    "                             ontology_data_location + 'ro_with_imports.owl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relations labels are already provided by PKL ecosystem\n",
    "download('RELATIONS_LABELS.txt', '../resources/relations_data/')\n",
    "download('INVERSE_RELATIONS.txt', '../resources/relations_data/')\n",
    "\n",
    "# Load data, print row count, and preview it\n",
    "ro_data_label = pandas.read_csv('../resources/relations_data/'+'RELATIONS_LABELS.txt', header=0, delimiter='\\t')\n",
    "\n",
    "print('There are {edge_count} RO Relations and Labels'.format(edge_count=len(ro_data_label)))\n",
    "ro_data_label.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Mondo Disease Ontology ([Mondo](https://www.ebi.ac.uk/ols/ontologies/ro))\n",
    "A semi-automatically constructed ontology that merges in multiple disease resources to yield a coherent merged ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ontology_data_location + 'mondo_with_imports.owl'):\n",
    "    command = '{} {} --merge-import-closure -o {}'\n",
    "    os.system(command.format(owltools_location, 'http://purl.obolibrary.org/obo/mondo.owl',\n",
    "                             ontology_data_location + 'mondo_with_imports.owl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, please run the [<tt>Ontology_Cleaning.ipynb</tt>](https://github.com/callahantiff/PheKnowLator/blob/master/notebooks/Ontology_Cleaning.ipynb) notebook provided by PKT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### DOWNLOAD EDGES  <a class=\"anchor\" id=\"create-edges\"></a>\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gene-disease from [Human Disease Molecular Mechanisms](https://github.com/callahantiff/PheKnowLator/wiki/Building-a-KG-of-Human-Disease-Molecular-Mechanisms) (PKT-built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downloader('https://storage.googleapis.com/pheknowlator/current_build/data/original_data/curated_gene_disease_associations.tsv',\n",
    "                edge_data_location)\n",
    "\n",
    "# Rename file adding relationship's identifier\n",
    "os.rename(edge_data_location+'curated_gene_disease_associations.tsv',\n",
    "          edge_data_location+'gene-disease_curated_gene_disease_associations.tsv')\n",
    "\n",
    "with open(edge_data_location + 'gene-disease_curated_gene_disease_associations.tsv') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = pd.read_csv(edge_data_location + 'gene-disease_curated_gene_disease_associations.tsv', sep=\"\\t\")  \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=50000)\n",
    "data.to_csv(edge_data_location + 'gene-disease_curated_gene_disease_associations.tsv', header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For representing genes, we can use NCBI Entrez Gene identifiers (<tt>geneID</tt> column), , and it's worth noting that symbols could have been a viable choice as well. For denoting diseases (<tt>diseaseID</tt> column), we can notice the original tsv adopts DisGeNET identifiers. We'll need to establish a mapping that links these identifiers to the Mondo ontology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### gene-miRNA from [TarBase](https://dianalab.e-ce.uth.gr/html/diana/web/index.php?r=tarbasev8/index)\n",
    "DIANA-TarBase v8 is a reference database devoted to the indexing of experimentally supported microRNA (miRNA) targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downloader('https://dianalab.e-ce.uth.gr/downloads/tarbase_v8_data.tar.gz', edge_data_location)\n",
    "\n",
    "with tarfile.TarFile(edge_data_location+'tarbase_v8_data.tar', 'r') as tar_ref:\n",
    "    tar_ref.extractall(edge_data_location)\n",
    "    \n",
    "# Remove tar file\n",
    "os.remove(edge_data_location+'tarbase_v8_data.tar')\n",
    "    \n",
    "# Rename file adding relationship's identifier\n",
    "os.rename(edge_data_location+'TarBase_v8_download.txt',\n",
    "          edge_data_location+'gene-miRNA_TarBase_v8_download.txt')   \n",
    "\n",
    "with open(edge_data_location + 'gene-miRNA_TarBase_v8_download.txt') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = pd.read_csv(edge_data_location + 'gene-miRNA_TarBase_v8_download.txt', sep=\"\\t\", dtype={\"cell_line\": \"string\"})  \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the time being, we keep only Homo sapiens rows\n",
    "data = data[data['species'].str.contains(\"Homo sapiens\")]\n",
    "\n",
    "# Moreover, we keep only 50k (random) rows to reduce input size\n",
    "data = data.sample(n=50000)\n",
    "\n",
    "# This simplified KG ignores if a transcript is \"3p\" or \"5p\", so we store this information as additional column\n",
    "data['p'] = data[data['mirna'].str.contains(\"p\")]['mirna']\n",
    "data[\"p\"] = data[\"p\"].str[-2:]\n",
    "data['mirna'] = data['mirna'].str.replace(r'-[35]p$', '', regex=True)\n",
    "data['mirna'] = data['mirna'].str.lower()\n",
    "\n",
    "# If you're interested in understanding why Homo sapiens has -3p and -5p miRNAs:\n",
    "# https://pubmed.ncbi.nlm.nih.gov/12592000/\n",
    "# Putting aside the -(3/5)p information, we are essentially dealing with non-mature (aka hairpin) miRNA:\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3616697/\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have only symbols and ENSG identifiers (<tt>geneId</tt> and <tt>geneName</tt> columns) for identifying genes, we'll require an additional mapping to link these symbols or ENSG to NCBI Entrez Gene identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(edge_data_location + 'gene-miRNA_TarBase_v8_download.txt', header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### miRNA-disease from [miR2Disease](http://watson.compbio.iupui.edu:8080/miR2Disease/)\n",
    "miR2Disease, a manually curated database, aims at providing a comprehensive resource of miRNA deregulation in various human diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downloader('http://watson.compbio.iupui.edu:8080/miR2Disease/download/AllEntries.txt', edge_data_location)\n",
    "\n",
    "data = pd.read_csv(edge_data_location + 'AllEntries.txt', sep=\"\\t\", header=None)  \n",
    "os.remove(edge_data_location + 'AllEntries.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miR2Disease provides a look-up table for mapping disease names to DO terms\n",
    "data_downloader('http://watson.compbio.iupui.edu:8080/miR2Disease/download/diseaseList.txt', processed_data_location)\n",
    "\n",
    "descDOmap = pd.read_csv(processed_data_location + 'diseaseList.txt', sep=\"\\t\")  \n",
    "os.remove(processed_data_location + 'diseaseList.txt')\n",
    "descDOmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ontologies are represented in OWL files that make use of _ for URIs\n",
    "descDOmap['disease ontology ID'] = descDOmap['disease ontology ID'].astype(str).str.replace(':', '_')\n",
    "\n",
    "disease2mirna = pd.merge(descDOmap, data, left_on=['disease name in original paper'], right_on=[1]).drop(\n",
    "    columns=['disease name in original paper'])\n",
    "disease2mirna[0] = disease2mirna[0].str.lower()\n",
    "disease2mirna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost 2,902-2,624=278 rows during mapping (278/2,902<10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease2mirna.to_csv(edge_data_location + 'miRNA-disease_miR2Disease.txt', header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### CREATE MAPPING DATASETS  <a class=\"anchor\" id=\"create-identifier-maps\"></a>\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembl Gene-Entrez Gene <a class=\"anchor\" id=\"ensemblgene-entrezgene\"></a>\n",
    "\n",
    "\n",
    "**Purpose:** To map Ensembl gene identifiers to Entrez gene identifiers\n",
    "\n",
    "**Output:** `ENSEMBL_GENE_ENTREZ_GENE_MAP.txt`\n",
    "\n",
    "Already provided by PKL ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('ENSEMBL_GENE_ENTREZ_GENE_MAP.txt', processed_data_location)\n",
    "\n",
    "ensEntrez = pd.read_csv(processed_data_location + 'ENSEMBL_GENE_ENTREZ_GENE_MAP.txt', sep=\"\\t\", header=None)\n",
    "ensEntrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### DisGeNET-Mondo <a class=\"anchor\" id=\"DisGeNET-Mondo\"></a>\n",
    "\n",
    "\n",
    "**Purpose:** To map DisGeNET identifiers to Mondo identifiers\n",
    "\n",
    "**Output:** `DISEASE_MONDO_MAP.txt`\n",
    "\n",
    "Already provided by PKL ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('DISEASE_MONDO_MAP.txt', processed_data_location)\n",
    "\n",
    "disMondo = pd.read_csv(processed_data_location + 'DISEASE_MONDO_MAP.txt', sep=\"\\t\", header=None)\n",
    "disMondo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Disease Ontology (DO) - Mondo mapping <a class=\"anchor\" id=\"ensemblgene-entrezgene\"></a>\n",
    "\n",
    "\n",
    "**Purpose:** To map DO identifiers to Mondo identifiers\n",
    "\n",
    "**Output:** `DISEASE_DOID_MONDO_Map.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mondo_graph = Graph().parse(ontology_data_location + 'mondo_with_imports.owl')\n",
    "\n",
    "dbxref_res = gets_ontology_class_dbxrefs(mondo_graph)[0]\n",
    "\n",
    "# Fix DOIDs (substitute : with _) and upper case them\n",
    "mondo_dict = {str(k).replace(':','_').upper(): {str(i).split('/')[-1].replace(':','_') for i in v}\n",
    "              for k, v in dbxref_res.items() if 'doid' in str(k)}\n",
    "\n",
    "with open(processed_data_location + 'DISEASE_DOID_MONDO_Map.txt', 'w') as outfile:\n",
    "    for k, v in mondo_dict.items():\n",
    "        outfile.write(str(k) + '\\t' + str(v).replace('{','').replace('\\'','').replace('}','') + '\\n')\n",
    " \n",
    "doidMondo = pd.read_csv(processed_data_location + 'DISEASE_DOID_MONDO_Map.txt', sep=\"\\t\", header=None)\n",
    "doidMondo[1] = doidMondo[1].str.split(',')\n",
    "doidMondo = doidMondo.explode(1)\n",
    "doidMondo.to_csv(processed_data_location + 'DISEASE_DOID_MONDO_Map.txt', header=None, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doidMondo = pd.read_csv(processed_data_location + 'DISEASE_DOID_MONDO_Map.txt', sep=\"\\t\", header=None)\n",
    "doidMondo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### miRBase ID - miRBase accession\n",
    "\n",
    "\n",
    "**Purpose:** To map miRNA identifiers from miRBase to miRBase accession (it guarantees a standard identification of miRNA molecules via URIs)\n",
    "\n",
    "**Output:** `MIRBASE_ID_ACCESSION_MAP.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downloader('https://www.mirbase.org/download/hsa.gff3', processed_data_location)\n",
    "\n",
    "miRBaseMap = gffpd.read_gff3(processed_data_location + 'hsa.gff3')  \n",
    "os.remove(processed_data_location + 'hsa.gff3')\n",
    "print(miRBaseMap.header)\n",
    "print(miRBaseMap.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRBaseMap = miRBaseMap.attributes_to_columns()\n",
    "miRBaseMap = miRBaseMap[['attributes']]\n",
    "miRBaseMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRBaseMap = miRBaseMap.attributes.str.split(';',expand=True)\n",
    "# Keep only \"ID\" and \"Name\" columns\n",
    "miRBaseMap = miRBaseMap[[2,0]]\n",
    "# Remove substring \"ID=\"\n",
    "miRBaseMap[0] = miRBaseMap[0].str[3:]\n",
    "# Remove substring \"Name=\"\n",
    "miRBaseMap[2] = miRBaseMap[2].str[5:]\n",
    "# Keep only hairpin/stem-loop miRNAs\n",
    "# (those starting with MI and not MIMAT, last one is reserved for mature sequences)\n",
    "miRBaseMap = miRBaseMap[~miRBaseMap[0].str.startswith('MIMAT')]\n",
    "miRBaseMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRBaseMap.to_csv(processed_data_location+'MIRBASE_ID_ACCESSION_MAP.txt', header=None,sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "To represent genes, PKT designates them as subclasses of relevant Sequence Ontology ([SO](https://www.ebi.ac.uk/ols4/ontologies/so)) terms. We add miRNAs as subclasses of [SO_0000647](http://purl.obolibrary.org/obo/SO_0000647) (*miRNA_primary_transcript*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KG construction approach dictionary (for non ontological data), provided by PKL ecosystem\n",
    "download('subclass_construction_map.pkl', '../resources/construction_approach/')\n",
    "\n",
    "# Load data, print row count, and preview it\n",
    "nonO_data = pd.read_pickle(r'../resources/construction_approach/subclass_construction_map.pkl')\n",
    "\n",
    "# For instance, ncbi IDs are mapped to appropriate SO Ontology entries\n",
    "list(nonO_data.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miRBaseMap['SO'] = [['SO_0000647']] * len(miRBaseMap)\n",
    "\n",
    "mirna_nonO = miRBaseMap.drop(2, axis=1).set_index(0).to_dict()\n",
    "nonO_data = {**nonO_data, **mirna_nonO['SO']}\n",
    "\n",
    "list(nonO_data.items())[len(list(nonO_data.items()))-5:len(list(nonO_data.items()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/construction_approach/subclass_construction_map.pkl', 'wb') as handle:\n",
    "    pickle.dump(nonO_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "PKT also provides node and relation metadata (a.k.a. node properties and relation attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KG metadata, provided by PKL ecosystem\n",
    "download('node_metadata_dict.pkl', '../resources/node_data/')\n",
    "\n",
    "# Load data, print row count, and preview it\n",
    "metadata = pd.read_pickle(r'../resources/node_data/node_metadata_dict.pkl')\n",
    "\n",
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: metadata['nodes'][k] for k in list(metadata['nodes'])[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: metadata['relations'][k] for k in list(metadata['relations'])[:5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add miRNA properties (*Label*, *Description*, and *Synonym*) from miRBase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "data_downloader('https://www.mirbase.org/download/miRNA.dat', processed_data_location)\n",
    "\n",
    "# Open the EMBL file\n",
    "embl_file = processed_data_location + 'miRNA.dat'\n",
    "\n",
    "# Create empty lists to store the data\n",
    "data = {\n",
    "    \"ID\": [],\n",
    "    \"Description\": [],\n",
    "    \"Sequence\": [],\n",
    "    \"Comments\": [],\n",
    "    \"References\": []\n",
    "}\n",
    "\n",
    "# Iterate through the records in the EMBL file\n",
    "for record in SeqIO.parse(embl_file, \"embl\"):\n",
    "    data[\"ID\"].append(record.id)\n",
    "    data[\"Description\"].append(record.description)\n",
    "    data[\"Sequence\"].append(str(record.seq))\n",
    "    data[\"Comments\"].append(str(record.annotations.get('comment', '')))\n",
    "    references = []\n",
    "    i = 0\n",
    "    for ref in record.annotations.get('references', []):\n",
    "        i = i + 1\n",
    "        references.append(f\"{[i], ref.pubmed_id}\")\n",
    "    data[\"References\"].append(\", \".join(references))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to \"ID\", \"Description\", and \"Synonym\" columns\n",
    "df = df[df['Description'].astype(str).str.contains('Homo sapiens')]\n",
    "df['Synonym'] = df['Description']\n",
    "df['Description'] = df['Comments'].astype(str) + df['References'].astype(str) + '. Sequence: ' + df['Sequence'].astype(str)\n",
    "df = df[['ID', 'Description', 'Synonym']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add *Labels* through the map we have previously developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, miRBaseMap, left_on=['ID'], right_on=[0])\n",
    "df['Label'] = df[2]\n",
    "df = df[['ID', 'Label', 'Description', 'Synonym']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to dictionary format\n",
    "miRNA_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    # Transform the ID to correspondent URI (KG's ID)\n",
    "    gene_id = f'https://www.mirbase.org/hairpin/{row[\"ID\"]}'\n",
    "    miRNA_dict[gene_id] = {\n",
    "        'Label': row['Label'],\n",
    "        'Description': row['Description'],\n",
    "        'Synonym': row['Synonym']\n",
    "    }\n",
    "    \n",
    "{k: miRNA_dict[k] for k in list(miRNA_dict)[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_dict = {**metadata.get('nodes'), **miRNA_dict}\n",
    "nodes_final_dict = {'nodes': nodes_dict}\n",
    "\n",
    "rel_dict = {'relations': {**metadata.get('relations')}}\n",
    "metadata = {**nodes_final_dict, **rel_dict}\n",
    "\n",
    "with open('../resources/node_data/node_metadata_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(metadata, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "If you wish to include additional bio-entities to enhance this KG, you will need to expand this dictionary. If you are interested, you can explore the entire [RNA-KG](https://github.com/AnacletoLAB/RNA-KG/). Feel free to contact me at [emanuele dot cavalleri at unimi dot it](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=emanuele.cavalleri@unimi.it)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
